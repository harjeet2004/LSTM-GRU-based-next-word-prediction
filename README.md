# ✍️ LSTM / GRU Next Word Prediction  

This repository contains an **AI-powered web application** built with **TensorFlow/Keras** and **Streamlit**, which predicts the **next word** in a given text sequence using **LSTM** and **GRU** models.  

The project demonstrates how recurrent neural networks can understand sequential patterns in natural language and generate meaningful continuations.  

---

## 🔗 Live App  

👉 [LSTM-GRU Next Word Predictor](https://lstm-gru-based-next-word-prediction-dcjiqti2gkkbudpeekdxep.streamlit.app/)  

---

## 📝 Project Description  

### 🔮 Next Word Prediction with RNNs  
- **Input:** Any sentence fragment (e.g., *“To be or not to”*)  
- **Output:**  
  - **Predicted Next Word** generated by either the **LSTM** or **GRU** model  
  - **Model Comparison Table** showing:  
    - Number of parameters  
    - Number of layers  
    - File size of the model  
    - Average inference time (ms)  
    - **Top-1 & Top-5 Accuracy** (evaluated on `hamlet.txt`)  

This project showcases the power of **Recurrent Neural Networks (RNNs)** like LSTMs and GRUs for text generation tasks.  

---

## 🛠 Technologies Used  

- **Python 3.10+**
- **TensorFlow / Keras**
- **Streamlit**
- **NumPy & Pandas**
- **Matplotlib**
- **Scikit-learn**
- **NLTK**
- **Git & GitHub**
- **Streamlit Cloud**

---

## 📁 Project Structure  

```
.
├── app.py                      # Streamlit web app for prediction
├── next_word_lstm.h5           # Trained LSTM model
├── next_word_lstm_GRU.h5       # Trained GRU model
├── tokenizer.pkl               # Tokenizer used for training & predictions
├── tokenizer.json              # Backup tokenizer in JSON format
├── hamlet.txt                  # Sample corpus for evaluation
├── experiments.ipynb           # Notebook for training & experimentation
├── requirements.txt            # Python dependencies
├── runtime.txt                 # Streamlit runtime environment
└── README.md                   # Project documentation
```

---

## 💻 How to Run Locally  

### 1. Clone the Repository  
```bash
git clone https://github.com/harjeet2004/LSTM-GRU-Next-Word-Prediction.git
cd LSTM-GRU-Next-Word-Prediction
```

### 2. Create & Activate a Virtual Environment  
```bash
conda create -n lstm-gru-env python=3.10
conda activate lstm-gru-env
```

### 3. Install Dependencies  
```bash
pip install -r requirements.txt
```

### 4. Run the Streamlit App  
```bash
streamlit run app.py
```

Visit:  
[http://localhost:8501](http://localhost:8501)  

---

## 🚀 How to Deploy on Streamlit Cloud  

1. Push your code & models (`.h5`, `tokenizer.pkl`, etc.) to GitHub  
2. Go to [Streamlit Cloud](https://streamlit.io/cloud)  
3. Click **New app** and link your repository  
4. Set the main file → `app.py`  
5. Add `requirements.txt` & `runtime.txt`  
6. Click **Deploy** 🎉  

---

## 🧠 What I Learned  

- Training **LSTM** and **GRU** models for text sequence prediction  
- Handling sequential data with **Keras Tokenizer** and `pad_sequences`  
- Evaluating models with **Top-1 & Top-5 accuracy** and **perplexity**  
- Measuring model latency and resource usage  
- Building interactive ML apps with **Streamlit**  
- Debugging issues with dependencies, environments, and deployment  
- Hosting ML applications on **Streamlit Cloud** for public access  

---

## 🙋‍♂️ Author  

Built with ❤️ by **Harjeet Singh Pannu** — a college student exploring **AI, NLP, and deep learning deployment in real-world applications**.  

---

## 📜 License  

This project is licensed under the **MIT License** — feel free to fork, extend, and contribute!  
