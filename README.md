# âœï¸ LSTM / GRU Next Word Prediction  

This repository contains an **AI-powered web application** built with **TensorFlow/Keras** and **Streamlit**, which predicts the **next word** in a given text sequence using **LSTM** and **GRU** models.  

The project demonstrates how recurrent neural networks can understand sequential patterns in natural language and generate meaningful continuations.  

---

## ğŸ”— Live App  

ğŸ‘‰ [LSTM-GRU Next Word Predictor](https://lstm-gru-based-next-word-prediction-dcjiqti2gkkbudpeekdxep.streamlit.app/)  

---

## ğŸ“ Project Description  

### ğŸ”® Next Word Prediction with RNNs  
- **Input:** Any sentence fragment (e.g., *â€œTo be or not toâ€*)  
- **Output:**  
  - **Predicted Next Word** generated by either the **LSTM** or **GRU** model  
  - **Model Comparison Table** showing:  
    - Number of parameters  
    - Number of layers  
    - File size of the model  
    - Average inference time (ms)  
    - **Top-1 & Top-5 Accuracy** (evaluated on `hamlet.txt`)  

This project showcases the power of **Recurrent Neural Networks (RNNs)** like LSTMs and GRUs for text generation tasks.  

---

## ğŸ›  Technologies Used  

- **Python 3.10+**
- **TensorFlow / Keras**
- **Streamlit**
- **NumPy & Pandas**
- **Matplotlib**
- **Scikit-learn**
- **NLTK**
- **Git & GitHub**
- **Streamlit Cloud**

---

## ğŸ“ Project Structure  

```
.
â”œâ”€â”€ app.py                      # Streamlit web app for prediction
â”œâ”€â”€ next_word_lstm.h5           # Trained LSTM model
â”œâ”€â”€ next_word_lstm_GRU.h5       # Trained GRU model
â”œâ”€â”€ tokenizer.pkl               # Tokenizer used for training & predictions
â”œâ”€â”€ tokenizer.json              # Backup tokenizer in JSON format
â”œâ”€â”€ hamlet.txt                  # Sample corpus for evaluation
â”œâ”€â”€ experiments.ipynb           # Notebook for training & experimentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ runtime.txt                 # Streamlit runtime environment
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸ’» How to Run Locally  

### 1. Clone the Repository  
```bash
git clone https://github.com/harjeet2004/LSTM-GRU-Next-Word-Prediction.git
cd LSTM-GRU-Next-Word-Prediction
```

### 2. Create & Activate a Virtual Environment  
```bash
conda create -n lstm-gru-env python=3.10
conda activate lstm-gru-env
```

### 3. Install Dependencies  
```bash
pip install -r requirements.txt
```

### 4. Run the Streamlit App  
```bash
streamlit run app.py
```

Visit:  
[http://localhost:8501](http://localhost:8501)  

---

## ğŸš€ How to Deploy on Streamlit Cloud  

1. Push your code & models (`.h5`, `tokenizer.pkl`, etc.) to GitHub  
2. Go to [Streamlit Cloud](https://streamlit.io/cloud)  
3. Click **New app** and link your repository  
4. Set the main file â†’ `app.py`  
5. Add `requirements.txt` & `runtime.txt`  
6. Click **Deploy** ğŸ‰  

---

## ğŸ§  What I Learned  

- Training **LSTM** and **GRU** models for text sequence prediction  
- Handling sequential data with **Keras Tokenizer** and `pad_sequences`  
- Evaluating models with **Top-1 & Top-5 accuracy** and **perplexity**  
- Measuring model latency and resource usage  
- Building interactive ML apps with **Streamlit**  
- Debugging issues with dependencies, environments, and deployment  
- Hosting ML applications on **Streamlit Cloud** for public access  

---

## ğŸ™‹â€â™‚ï¸ Author  

Built with â¤ï¸ by **Harjeet Singh Pannu** â€” a college student exploring **AI, NLP, and deep learning deployment in real-world applications**.  

---

## ğŸ“œ License  

This project is licensed under the **MIT License** â€” feel free to fork, extend, and contribute!  
